{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code preface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nums of GPU Available 1\n"
     ]
    }
   ],
   "source": [
    "# to see the number of GPU available\n",
    "print(\"Nums of GPU Available\",len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieSamples = pd.read_csv('movies.csv')\n",
    "ratingSamples = pd.read_csv('ratings.csv')\n",
    "userGenres = pd.read_csv('userGenres.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSampleLabel(ratingSamples):\n",
    "    # Rating > 3.5 will label positive to that movie(1)\n",
    "    ratingSamples['label'] = np.where(ratingSamples['rating']>=3.5, 1, 0)\n",
    "    return ratingSamples\n",
    "\n",
    "def addMovieFeatures(movieSamples, ratingSamplesWithLabel):\n",
    "    samplesWithMovies1 = ratingSamples.join(movieSamples.set_index(['movieId'],verify_integrity=True), \n",
    "                                        on=['movieId'], how='left')\n",
    "    #Extract release year\n",
    "    samplesWithMovies1['releaseYear'] = np.where(samplesWithMovies1['title'].str.len()<6, 1990\n",
    "                                             ,samplesWithMovies1['title'].str.slice(-5, -1))\n",
    "    \n",
    "    samplesWithMovies1.drop(['title'],axis = 1,inplace = True)\n",
    "    \n",
    "    #Extract top-3 movie genre\n",
    "    samplesWithMovies1[['movieGenre1', 'movieGenre2', 'movieGenre3']] = samplesWithMovies1['genres'].str.split(\"|\",expand=True)[[0,1,2]]\n",
    "    \n",
    "    #Get movie avh,std,count of rating\n",
    "    rating = samplesWithMovies1.groupby('movieId')['rating'].agg(['count', 'mean', 'std'])\n",
    "    samplesWithMovies2 = samplesWithMovies1.join(rating,on = ['movieId'],how = 'left')\n",
    "    samplesWithMovies3 = samplesWithMovies1.rename(columns={\"count\": \"movieRatingCount\", \"mean\": \"movieAvgRating\",\"std\":\"movieRatingStddev\"})\n",
    "    \n",
    "    return  samplesWithMovies3\n",
    "\n",
    "\n",
    "def addUserFeatures(samplesWithMovieFeatures,userGenres):\n",
    "    # Order by timestamp\n",
    "    t = samplesWithMovieFeatures.sort_values(['timestamp'],ascending=False)[samplesWithMovieFeatures['label']==1].groupby('userId')['movieId'].apply(list)\n",
    "    t = t.to_frame()\n",
    "    t = t.rename(columns = {\"movieId\": \"userPositiveHistory\"})\n",
    "    \n",
    "    #Get user rating history order by time\n",
    "    t['liststring'] = [','.join(map(str, l)) for l in t['userPositiveHistory']]\n",
    "    t[['userRatedMovie1', 'userRatedMovie2', 'userRatedMovie3','userRatedMovie4','userRatedMovie5']] = t['liststring'].str.split(\",\",expand=True)[[0,1,2,3,4]]\n",
    "    t.drop(['userPositiveHistory','liststring'],axis = 1,inplace = True)\n",
    "    \n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.join(t,on = 'userId',how = 'left', rsuffix='_right')\n",
    "    \n",
    "    #Get avg,std,count of user rating history\n",
    "    rating = samplesWithMovieFeatures.groupby('userId')['rating'].agg(['count', 'mean', 'std'])\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.join(rating,on = ['userId'],how = 'left')\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.rename(columns={\"count\": \"userRatingCount\", \"mean\": \"userAvgRating\",\"std\":\"userRatingStddev\"})\n",
    "    \n",
    "    #Get release year of movie that user rated\n",
    "    samplesWithMovieFeatures['releaseYear'] = pd.to_numeric(samplesWithMovieFeatures['releaseYear'])\n",
    "    rating = samplesWithMovieFeatures.groupby('userId')['releaseYear'].agg(['mean', 'std'])\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.join(rating,on = ['userId'],how = 'left')\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.rename(columns={\"mean\": \"userAvgReleaseYear\",\"std\":\"userReleaseYearStddev\"})\n",
    "\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures.join(userGenres,on = 'userId',how = 'left', rsuffix='_right')\n",
    "    \n",
    "    #Delete users that ratingcount<=1\n",
    "    samplesWithMovieFeatures = samplesWithMovieFeatures[samplesWithMovieFeatures.userRatingCount>1]\n",
    "    \n",
    "    return samplesWithMovieFeatures\n",
    "\n",
    "def splitAndSaveTrainingTestSamples(samplesWithUserFeatures):\n",
    "    train, test = train_test_split(samplesWithUserFeatures, test_size=0.2)\n",
    "    train.to_csv(r'train.csv', index = False, header=True)\n",
    "    test.to_csv(r'test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    movieSamples = pd.read_csv('movies.csv')\n",
    "    ratingSamples = pd.read_csv('ratings.csv')\n",
    "    userGenres = pd.read_csv('userGenres.csv')\n",
    "    \n",
    "    #movieResourcesPath = file_path + \"/Movie Recommand/movies.csv\"\n",
    "    #ratingsResourcesPath = file_path + \"/Movie Recommand/ratings.csv\"\n",
    "    ratingSamplesWithLabel = addSampleLabel(ratingSamples)\n",
    "    \n",
    "    samplesWithMovieFeatures = addMovieFeatures(movieSamples, ratingSamplesWithLabel)\n",
    "    \n",
    "    samplesWithUserFeatures = addUserFeatures(samplesWithMovieFeatures,userGenres)\n",
    "    # save samples as csv format\n",
    "    splitAndSaveTrainingTestSamples(samplesWithUserFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training samples path\n",
    "training_samples_file_path = tf.keras.utils.get_file(\"trainingSamples.csv\",\"file:///Users/yutinggong/Desktop/Research/trainingSamples.csv\")\n",
    "# Test samples path\n",
    "test_samples_file_path = tf.keras.utils.get_file(\"testSamples.csv\",\n",
    "                                                 \"file:///Users/yutinggong/Desktop/Research/testSamples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Epoch 1/10\n",
      "   7403/Unknown - 189s 26ms/step - loss: 0.7295 - accuracy: 0.6121 - auc: 0.6369 - auc_1: 0.6730WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 189s 26ms/step - loss: 0.7295 - accuracy: 0.6121 - auc: 0.6369 - auc_1: 0.6730\n",
      "Epoch 2/10\n",
      "7400/7403 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.6785 - auc: 0.7288 - auc_1: 0.7543WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 174s 24ms/step - loss: 0.6045 - accuracy: 0.6785 - auc: 0.7289 - auc_1: 0.7543\n",
      "Epoch 3/10\n",
      "7402/7403 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7211 - auc: 0.7871 - auc_1: 0.8068WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 174s 24ms/step - loss: 0.5515 - accuracy: 0.7211 - auc: 0.7871 - auc_1: 0.8068\n",
      "Epoch 4/10\n",
      "7402/7403 [============================>.] - ETA: 0s - loss: 0.5117 - accuracy: 0.7510 - auc: 0.8215 - auc_1: 0.8407WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 177s 24ms/step - loss: 0.5118 - accuracy: 0.7510 - auc: 0.8215 - auc_1: 0.8407\n",
      "Epoch 5/10\n",
      "7402/7403 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.7690 - auc: 0.8433 - auc_1: 0.8628WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 176s 24ms/step - loss: 0.4838 - accuracy: 0.7690 - auc: 0.8433 - auc_1: 0.8628\n",
      "Epoch 6/10\n",
      "7400/7403 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.7788 - auc: 0.8556 - auc_1: 0.8757WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 174s 23ms/step - loss: 0.4669 - accuracy: 0.7788 - auc: 0.8556 - auc_1: 0.8757\n",
      "Epoch 7/10\n",
      "7402/7403 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.7874 - auc: 0.8657 - auc_1: 0.8865WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 175s 24ms/step - loss: 0.4519 - accuracy: 0.7873 - auc: 0.8657 - auc_1: 0.8864\n",
      "Epoch 8/10\n",
      "7401/7403 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.7935 - auc: 0.8725 - auc_1: 0.8934WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 177s 24ms/step - loss: 0.4410 - accuracy: 0.7935 - auc: 0.8725 - auc_1: 0.8934\n",
      "Epoch 9/10\n",
      "7401/7403 [============================>.] - ETA: 0s - loss: 0.4319 - accuracy: 0.7981 - auc: 0.8783 - auc_1: 0.8991WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 175s 24ms/step - loss: 0.4318 - accuracy: 0.7981 - auc: 0.8783 - auc_1: 0.8991\n",
      "Epoch 10/10\n",
      "7402/7403 [============================>.] - ETA: 0s - loss: 0.4237 - accuracy: 0.8015 - auc: 0.8831 - auc_1: 0.9039WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "7403/7403 [==============================] - 176s 24ms/step - loss: 0.4237 - accuracy: 0.8015 - auc: 0.8831 - auc_1: 0.9039\n",
      "   1870/Unknown - 37s 20ms/step - loss: 0.6897 - accuracy: 0.6677 - auc: 0.7317 - auc_1: 0.7573- 29s 20ms/step - loss: 0.6890 - accuracy: 0.6666 - auc: 0.7314 - auc_1: 0.758 - 29s 2  - 33s 20ms/step - loss: 0.6866 - accuracy: 0.6681 - auc: 0.732 - 34s - 35s 20ms/step - loss: 0.6872 - accuracy: 0.6683 - 36s 20ms/step - loss: 0.6878 - accuracy: 0.6681 - auc:  - 36s \n",
      "\n",
      "Test Loss 0.6896694982912451, Test Accuracy 0.6677361726760864, Test ROC AUC 0.7316500544548035, Test PR AUC 0.7572778463363647\n",
      "Predicted good rating: 53.68%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 17.89%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 71.54%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 69.76%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 26.09%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 71.23%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 75.28%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 73.25%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 16.49%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 21.38%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 33.38%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 99.69%  | Actual rating label:  Bad Rating\n"
     ]
    }
   ],
   "source": [
    "# load sample as tf dataset\n",
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=12,\n",
    "        label_name='label',\n",
    "        na_value=\"0\",\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# split as test dataset and training dataset\n",
    "train_dataset = get_dataset(training_samples_file_path)\n",
    "test_dataset = get_dataset(test_samples_file_path)\n",
    "\n",
    "# genre features vocabulary\n",
    "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
    "               'Sci-Fi', 'Drama', 'Thriller',\n",
    "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n",
    "\n",
    "GENRE_FEATURES = {\n",
    "    'userGenre1': genre_vocab,\n",
    "    'userGenre2': genre_vocab,\n",
    "    'userGenre3': genre_vocab,\n",
    "    'userGenre4': genre_vocab,\n",
    "    'userGenre5': genre_vocab,\n",
    "    'movieGenre1': genre_vocab,\n",
    "    'movieGenre2': genre_vocab,\n",
    "    'movieGenre3': genre_vocab\n",
    "}\n",
    "\n",
    "# all categorical features\n",
    "categorical_columns = []\n",
    "for feature, vocab in GENRE_FEATURES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature, vocabulary_list=vocab)\n",
    "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
    "    categorical_columns.append(emb_col)\n",
    "# movie id embedding feature\n",
    "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1001)\n",
    "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
    "categorical_columns.append(movie_emb_col)\n",
    "\n",
    "# user id embedding feature\n",
    "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=30001)\n",
    "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
    "categorical_columns.append(user_emb_col)\n",
    "\n",
    "# all numerical features\n",
    "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
    "                     tf.feature_column.numeric_column('movieRatingCount'),\n",
    "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
    "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
    "                     tf.feature_column.numeric_column('userRatingCount'),\n",
    "                     tf.feature_column.numeric_column('userAvgRating'),\n",
    "                     tf.feature_column.numeric_column('userRatingStddev')]\n",
    "\n",
    "# cross feature between current movie and user historical movie\n",
    "rated_movie = tf.feature_column.categorical_column_with_identity(key='userRatedMovie1', num_buckets=1001)\n",
    "crossed_feature = tf.feature_column.indicator_column(tf.feature_column.crossed_column([movie_col, rated_movie], 10000))\n",
    "\n",
    "# define input for keras model\n",
    "inputs = {\n",
    "    'movieAvgRating': tf.keras.layers.Input(name='movieAvgRating', shape=(), dtype='float32'),\n",
    "    'movieRatingStddev': tf.keras.layers.Input(name='movieRatingStddev', shape=(), dtype='float32'),\n",
    "    'movieRatingCount': tf.keras.layers.Input(name='movieRatingCount', shape=(), dtype='int32'),\n",
    "    'userAvgRating': tf.keras.layers.Input(name='userAvgRating', shape=(), dtype='float32'),\n",
    "    'userRatingStddev': tf.keras.layers.Input(name='userRatingStddev', shape=(), dtype='float32'),\n",
    "    'userRatingCount': tf.keras.layers.Input(name='userRatingCount', shape=(), dtype='int32'),\n",
    "    'releaseYear': tf.keras.layers.Input(name='releaseYear', shape=(), dtype='int32'),\n",
    "\n",
    "    'movieId': tf.keras.layers.Input(name='movieId', shape=(), dtype='int32'),\n",
    "    'userId': tf.keras.layers.Input(name='userId', shape=(), dtype='int32'),\n",
    "    'userRatedMovie1': tf.keras.layers.Input(name='userRatedMovie1', shape=(), dtype='int32'),\n",
    "\n",
    "    'userGenre1': tf.keras.layers.Input(name='userGenre1', shape=(), dtype='string'),\n",
    "    'userGenre2': tf.keras.layers.Input(name='userGenre2', shape=(), dtype='string'),\n",
    "    'userGenre3': tf.keras.layers.Input(name='userGenre3', shape=(), dtype='string'),\n",
    "    'userGenre4': tf.keras.layers.Input(name='userGenre4', shape=(), dtype='string'),\n",
    "    'userGenre5': tf.keras.layers.Input(name='userGenre5', shape=(), dtype='string'),\n",
    "    'movieGenre1': tf.keras.layers.Input(name='movieGenre1', shape=(), dtype='string'),\n",
    "    'movieGenre2': tf.keras.layers.Input(name='movieGenre2', shape=(), dtype='string'),\n",
    "    'movieGenre3': tf.keras.layers.Input(name='movieGenre3', shape=(), dtype='string'),\n",
    "}\n",
    "\n",
    "# wide and deep model architecture\n",
    "# deep part for all input features\n",
    "deep = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)(inputs)\n",
    "deep = tf.keras.layers.Dense(128, activation='relu')(deep)\n",
    "deep = tf.keras.layers.Dense(128, activation='relu')(deep)\n",
    "# wide part for cross feature\n",
    "wide = tf.keras.layers.DenseFeatures(crossed_feature)(inputs)\n",
    "both = tf.keras.layers.concatenate([deep, wide])\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
    "model = tf.keras.Model(inputs, output_layer)\n",
    "\n",
    "# compile the model, set loss function, optimizer and evaluation metrics\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(curve = 'ROC'),tf.keras.metrics.AUC(curve = 'PR')])\n",
    "\n",
    "checkpoint_filepath = '/Users/lifan/Desktop/Movie'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "model.fit(train_dataset,epochs=10,shuffle = True,callbacks=[model_checkpoint_callback])\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "#model.load_weights(checkpoint_filepath)\n",
    "\n",
    "#model.fit(train_dataset, epochs=5)\n",
    "#model.save_weights('checkpoint')\n",
    "\n",
    "# evaluate the model\n",
    "test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}, Test ROC AUC {}, Test PR AUC {}'.format(test_loss, test_accuracy,\n",
    "                                                                                   test_roc_auc, test_pr_auc))\n",
    "\n",
    "# print some predict results\n",
    "predictions = model.predict(test_dataset)\n",
    "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
    "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
    "          \" | Actual rating label: \",\n",
    "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
